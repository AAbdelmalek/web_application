{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\587281\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n",
      "C:\\Users\\587281\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1007, \"Can't create database 'web_app_dev'; database exists\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Youtuber's Name: SELECT *FROM artists\n",
      "SELECT *FROM artists\n",
      "How far back in time do you want to go? (YYYY-MM-DD) or (all-time): all-time\n",
      "all-time\n",
      "https://www.youtube.com/results?search_query=SELECT+*FROM+artists\n",
      "https://www.youtube.com/user/TheCanDanceNetwork/videos\n",
      "https://www.youtube.com/user/TheCanDanceNetwork/about\n",
      "Artist: TheCanDanceNetwork\n",
      "Subscribers: 8\n",
      "Views: 1154\n",
      "Joined: 2013-02-04 00:00:00\n",
      "Not found in database\n",
      "https://www.youtube.com/playlist?list=UUkuHl-JqlnJIPR6OlDvPxPw\n",
      "https://www.youtube.com/watch?v=d24yAOSkBe0&list=UUkuHl-JqlnJIPR6OlDvPxPw\n",
      "Total videos: 7\n",
      "Getting urls...\n",
      "14.29% complete...\n",
      "28.57% complete...\n",
      "42.86% complete...\n",
      "57.14% complete...\n",
      "71.43% complete...\n",
      "85.71% complete...\n",
      "100.0% complete...\n",
      "Inserting data into database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\587281\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1050, \"Table 'artists' already exists\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted data into database successfully...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Scrape_Date</th>\n",
       "      <th>Search_Name</th>\n",
       "      <th>Joined</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Total_Views</th>\n",
       "      <th>Published</th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Paid</th>\n",
       "      <th>Family_Friendly</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>Agents</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=d24yAOSkBe0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>What is The CanDance Network?</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=lZPK65aZm7E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>Networking</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>4.183333</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=3H5MO6-gCvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>Press Kits</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=rvW4xpIWIRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>Introducing Your Work</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=NH0K0eFEu-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>How do you select artists?</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>3.633333</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=9xlOEtnznXM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TheCanDanceNetwork</td>\n",
       "      <td>2018-12-17 21:54:24.931060</td>\n",
       "      <td>SELECT *FROM artists</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1154</td>\n",
       "      <td>2013-03-04</td>\n",
       "      <td>Ask a Presenter Teaser</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.youtube.com/watch?v=IRFXRBuExxg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Artist                Scrape_Date           Search_Name  \\\n",
       "0  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "1  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "2  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "3  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "4  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "5  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "6  TheCanDanceNetwork 2018-12-17 21:54:24.931060  SELECT *FROM artists   \n",
       "\n",
       "      Joined  Subscribers  Total_Views  Published  \\\n",
       "0 2013-02-04            8         1154 2013-11-01   \n",
       "1 2013-02-04            8         1154 2013-10-31   \n",
       "2 2013-02-04            8         1154 2013-10-31   \n",
       "3 2013-02-04            8         1154 2013-10-30   \n",
       "4 2013-02-04            8         1154 2013-10-30   \n",
       "5 2013-02-04            8         1154 2013-10-30   \n",
       "6 2013-02-04            8         1154 2013-03-04   \n",
       "\n",
       "                           Title       Category  Duration  Views  Likes  \\\n",
       "0                         Agents  Howto & Style  2.900000    106      0   \n",
       "1  What is The CanDance Network?  Howto & Style  5.333333    152      0   \n",
       "2                     Networking  Howto & Style  4.183333    149      0   \n",
       "3                     Press Kits  Howto & Style  4.966667    136      1   \n",
       "4          Introducing Your Work  Howto & Style  4.800000    382      0   \n",
       "5     How do you select artists?  Howto & Style  3.633333    156      0   \n",
       "6         Ask a Presenter Teaser  Howto & Style  3.766667     68      0   \n",
       "\n",
       "   Dislikes   Paid Family_Friendly  \\\n",
       "0         0  False            True   \n",
       "1         0  False            True   \n",
       "2         0  False            True   \n",
       "3         0  False            True   \n",
       "4         0  False            True   \n",
       "5         0  False            True   \n",
       "6         0  False            True   \n",
       "\n",
       "                                           URL  \n",
       "0  https://www.youtube.com/watch?v=d24yAOSkBe0  \n",
       "1  https://www.youtube.com/watch?v=lZPK65aZm7E  \n",
       "2  https://www.youtube.com/watch?v=3H5MO6-gCvc  \n",
       "3  https://www.youtube.com/watch?v=rvW4xpIWIRY  \n",
       "4  https://www.youtube.com/watch?v=NH0K0eFEu-g  \n",
       "5  https://www.youtube.com/watch?v=9xlOEtnznXM  \n",
       "6  https://www.youtube.com/watch?v=IRFXRBuExxg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To do:\n",
    "# Fix Dates, must be another published on vs premiered on discrepancy -- OK\n",
    "# Fix Titles -- OK\n",
    "# Looks like missing one (1) video for Gibi 344/345 -- OK\n",
    "# DUPLICATES -- OK\n",
    "# EDGE CASES ▶ -- OK\n",
    "# User entered date range -- OK\n",
    "# Limit Date Range to Years and then YTD, e.g. 2016, 2017, YTD, All-Time\n",
    "# Better commenting -- OK\n",
    "# Duration -- OK\n",
    "# Flask -- \n",
    "# HTML/CSS/JS -- \n",
    "# Dev Database -- OK\n",
    "# Wrong Date bug -- \n",
    "# DB Date Bug - hours path - messed up datetime object -- OK\n",
    "# Escape SQL -- \n",
    "# Cached Scrapes -- OK\n",
    "\n",
    "# Import Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# Get Scrape Date\n",
    "scrape_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "scrape_datetime = datetime.utcnow()\n",
    "\n",
    "# Connect to Database\n",
    "connection = create_engine('mysql://root:Mars@127.0.0.1')\n",
    "\n",
    "# Creating database if not exists\n",
    "connection.execute(\"CREATE DATABASE IF NOT EXISTS web_app_dev\")\n",
    "connection.execute(\"USE web_app_dev\")\n",
    "\n",
    "# Convert Date from Jan 1, 1999 format to datetime object\n",
    "converted_date = \"\"\n",
    "raw_months = {\"Jan\": 1, \"Feb\": 2, \"Mar\" : 3, \"Apr\" : 4, \n",
    "              \"May\" : 5, \"Jun\" : 6, \"Jul\" : 7, \"Aug\" : 8,\n",
    "              \"Sep\" : 9, \"Oct\" : 10, \"Nov\" : 11, \"Dec\" : 12}\n",
    "\n",
    "def convertDate(raw_date):\n",
    "    \n",
    "    try:\n",
    "        converted_date = \"\"\n",
    "        number_month = raw_months.get(raw_date[0])\n",
    "        date_str = (str(number_month) + \"/\" + raw_date[1] + \"/\" + raw_date[2]).replace(\",\", \"\")\n",
    "        converted_date = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "        return converted_date\n",
    "        \n",
    "    except:\n",
    "        print(f\"{raw_date} Convert function date is not valid.\")\n",
    "\n",
    "# Get Youtuber's Name\n",
    "input_name = input(\"Enter Youtuber's Name: \")\n",
    "print(input_name)\n",
    "\n",
    "input_date_range = input(\"How far back in time do you want to go? (YYYY-MM-DD) or (all-time): \")\n",
    "print(input_date_range)\n",
    "\n",
    "if input_date_range == \"all-time\":\n",
    "    converted_input_date = datetime.strptime(\"1950-01-01\", '%Y-%m-%d')\n",
    "    \n",
    "else:\n",
    "    try:\n",
    "        converted_input_date = datetime.strptime(input_date_range, '%Y-%m-%d')\n",
    "        \n",
    "    except:\n",
    "        print(\"Input date is not valid.\")\n",
    "        exit()\n",
    "\n",
    "list_name = input_name.split()\n",
    "\n",
    "converted_name = input_name\n",
    "\n",
    "if len(list_name) > 1:\n",
    "    \n",
    "    converted_name = \"\"\n",
    "    \n",
    "    for i in range(len(list_name)):\n",
    "\n",
    "        converted_name = converted_name + list_name[i]\n",
    "        \n",
    "        if i != len(list_name)-1:\n",
    "            converted_name = converted_name + \"+\"\n",
    "\n",
    "search_name = converted_name\n",
    "start_url = \"https://www.youtube.com/results?search_query=\" + search_name\n",
    "\n",
    "print(start_url)\n",
    "\n",
    "get_youtube_url_response = requests.get(start_url)\n",
    "youtube_name_soup = bs(get_youtube_url_response.text, \"lxml\")\n",
    "raw_youtube_name_link = youtube_name_soup.find_all(\"div\", class_=\"yt-lockup-byline\")[0].a.get(\"href\")\n",
    "videos_link = \"https://www.youtube.com\" + raw_youtube_name_link + \"/videos\"\n",
    "about_link = \"https://www.youtube.com\" + raw_youtube_name_link + \"/about\"\n",
    "\n",
    "print(videos_link)\n",
    "print(about_link)\n",
    "\n",
    "# Get About Information\n",
    "about_html = requests.get(about_link)\n",
    "\n",
    "# Parse HTML\n",
    "about_soup = bs(about_html.text, \"lxml\")\n",
    "\n",
    "# Artist Information\n",
    "artist_name = about_soup.find(\"meta\", property=\"og:title\").get(\"content\")\n",
    "\n",
    "subscribers = about_soup.find_all(\"span\", class_=\"about-stat\")[0].text\n",
    "subscribers_int = int(subscribers.split(\" \")[0].replace(\",\",\"\"))\n",
    "\n",
    "total_views = about_soup.find_all(\"span\", class_=\"about-stat\")[1].text\n",
    "total_views_int = int(total_views[3:len(total_views)].split(\" \")[0].replace(\",\",\"\"))\n",
    "\n",
    "joined = about_soup.find_all(\"span\", class_=\"about-stat\")[2].text\n",
    "joined_temp = joined.split(\" \")[1:4]\n",
    "joined_convert = convertDate(joined_temp)\n",
    "\n",
    "print(f\"Artist: {artist_name}\")\n",
    "print(f\"Subscribers: {subscribers_int}\")\n",
    "print(f\"Views: {total_views_int}\")\n",
    "print(f\"Joined: {joined_convert}\")\n",
    "\n",
    "# Replacing spaces withunderscores for new table name\n",
    "artist_db_name = artist_name.replace(\" \",\"_\")\n",
    "\n",
    "# Checking Database to See if Data was Previously Scraped\n",
    "df_cache = []\n",
    "try:\n",
    "    df_cache = pd.read_sql(f\"SELECT artists.ARTIST, artists.SCRAPE_DATE, artists.SEARCH_NAME, JOINED, SUBSCRIBERS, TOTAL_VIEWS, \\\n",
    "    {artist_db_name}.PUBLISHED, \\\n",
    "    {artist_db_name}.TITLE, {artist_db_name}.CATEGORY , {artist_db_name}.DURATION, {artist_db_name}.VIEWS, \\\n",
    "    {artist_db_name}.LIKES, {artist_db_name}.DISLIKES, {artist_db_name}.PAID, {artist_db_name}.FAMILY_FRIENDLY, \\\n",
    "    {artist_db_name}.URL FROM artists \\\n",
    "    INNER JOIN {artist_db_name} \\\n",
    "    ON artists.artist = {artist_db_name}.artist\",connection)\n",
    "    \n",
    "except:\n",
    "    print(\"Not found in database\")\n",
    "\n",
    "if len(df_cache) != 0:\n",
    "    scrape_date = df_cache.loc[0,\"SCRAPE_DATE\"]\n",
    "    print(f\"A cached scrape ({scrape_date} UTC) has been found...\")\n",
    "    display(df_cache)\n",
    "    \n",
    "else:\n",
    "    # Convert User Name to UU Format\n",
    "    youtube_code = raw_youtube_name_link.split(\"/\")[2]\n",
    "\n",
    "    if youtube_code[0:2] == \"UC\":\n",
    "\n",
    "        youtube_code = raw_youtube_name_link.split(\"/\")[2]\n",
    "        playlist_link = \"https://www.youtube.com\" + \"/playlist?list=UU\" + youtube_code[2:] \n",
    "\n",
    "    elif youtube_code[0:2] != \"UC\":\n",
    "\n",
    "        youtube_code_raw = about_soup.find(\"link\", rel=\"canonical\").get(\"href\")\n",
    "        youtube_code = youtube_code_raw.split(\"/\")[4]\n",
    "        playlist_link = \"https://www.youtube.com\" + \"/playlist?list=UU\" + youtube_code[2:]  \n",
    "\n",
    "    print(playlist_link)\n",
    "\n",
    "    # Get Playlist Response\n",
    "    playlist_response = requests.get(playlist_link)\n",
    "\n",
    "    # Create Playlist Soup Object\n",
    "    playlist_soup = bs(playlist_response.text, 'lxml')\n",
    "\n",
    "    # Get First Video URL as Starting Point\n",
    "    first_video = \"https://www.youtube.com\" + playlist_soup.find_all(\"a\", class_=\"pl-video-title-link\")[0].get(\"href\").split(\"&\")[0]\n",
    "    first_video_within_playlist = first_video + \"&\" + playlist_link.split(\"?\")[1]\n",
    "\n",
    "    print(first_video_within_playlist)\n",
    "\n",
    "    # Create Soup Object for First Video Inside Playlist\n",
    "    playlist_inside_request = requests.get(first_video_within_playlist) \n",
    "\n",
    "    playlist_inside_soup = bs(playlist_inside_request.text, \"lxml\")\n",
    "\n",
    "    urls_all = []\n",
    "    total_videos_in_playlist = int(playlist_inside_soup.find(\"span\", id=\"playlist-length\").text.replace(\" videos\",\"\").replace(\",\",\"\"))\n",
    "    print(f\"Total videos: {total_videos_in_playlist}\")\n",
    "    number_of_videos_in_page = len(playlist_inside_soup.find_all(\"span\", class_=\"index\")) \n",
    "    last_video_index = int(playlist_inside_soup.find_all(\"span\", class_=\"index\")[-1].text.replace(\"\\n        \",\"\").replace(\"\\n    \",\"\"))\n",
    "    last_shown_link = playlist_inside_soup.find_all(\"span\", class_=\"index\")[-1].find_next(\"a\").get(\"href\")\n",
    "    link_fix = \"https://www.youtube.com\" + last_shown_link\n",
    "\n",
    "    # proceed = input(\"Proceed with scrape? (y/n)\")\n",
    "\n",
    "    # if proceed == \"n\" or proceed == \"N\":\n",
    "    #     exit()\n",
    "\n",
    "    print(\"Getting urls...\")\n",
    "\n",
    "    for i in range(total_videos_in_playlist):   \n",
    "\n",
    "        if i == 0:       \n",
    "            first_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        ▶\\n    \")\n",
    "            url = \"https://www.youtube.com\" + first_link.find_next(\"a\").get(\"href\")\n",
    "            original_url = url.split(\"&\")[0]\n",
    "            urls_all.append(original_url)\n",
    "            next_link = first_link\n",
    "\n",
    "        elif i == last_video_index:       \n",
    "            playlist_inside_request = requests.get(link_fix)\n",
    "            playlist_inside_soup = bs(playlist_inside_request.text, \"lxml\")\n",
    "            last_shown_link = playlist_inside_soup.find_all(\"span\", class_=\"index\")[-1].find_next(\"a\").get(\"href\")\n",
    "            link_fix = \"https://www.youtube.com\" + last_shown_link\n",
    "            last_video_index = int(playlist_inside_soup.find_all(\"span\", class_=\"index\")[-1].text.replace(\"\\n        \",\"\").replace(\"\\n    \",\"\"))\n",
    "            first_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        {i+1}\\n    \")\n",
    "\n",
    "            if first_link is None:           \n",
    "                next_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        ▶\\n    \")\n",
    "\n",
    "            else:          \n",
    "                next_link = first_link\n",
    "\n",
    "            next_url = \"https://www.youtube.com\" + next_link.find_next(\"a\").get(\"href\")\n",
    "            original_url = next_url.split(\"&\")[0]\n",
    "            urls_all.append(original_url)\n",
    "            number_of_videos_in_page = len(playlist_inside_soup.find_all(\"span\", class_=\"index\")) - 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            if i == 1:\n",
    "                first_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        ▶\\n    \")\n",
    "\n",
    "            elif playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        {i}\\n    \") is None:\n",
    "                first_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        ▶\\n    \")\n",
    "\n",
    "            else:\n",
    "                first_link = playlist_inside_soup.find(\"span\", class_=\"index\", text=f\"\\n        {i}\\n    \")\n",
    "\n",
    "            next_link = first_link\n",
    "            next_link = next_link.find_next(\"span\", class_=\"index\")\n",
    "            next_url = \"https://www.youtube.com\" + next_link.find_next(\"a\").get(\"href\")\n",
    "            original_url = next_url.split(\"&\")[0]\n",
    "            urls_all.append(original_url)\n",
    "\n",
    "    # Going to Each Video and Extracting Data\n",
    "    published_on = []\n",
    "    raw_published_on = []\n",
    "    views = []\n",
    "    date = []\n",
    "    duration_videos = []\n",
    "    likes = []\n",
    "    dislikes = []\n",
    "    title_videos = []\n",
    "    categories = []\n",
    "    paid_list = []\n",
    "    family_friendly = []\n",
    "\n",
    "    for i in range(len(urls_all)):\n",
    "\n",
    "        video_url = urls_all[i]\n",
    "        video_response = requests.get(video_url)\n",
    "        video_soup = bs(video_response.text, 'lxml')\n",
    "\n",
    "        # Publish Date\n",
    "        raw_publish_date = video_soup.find(\"div\", id=\"watch-uploader-info\").text\n",
    "        raw_published_on.append(raw_publish_date)\n",
    "\n",
    "        # Handle All Raw Dates \"Premiered\", \"\"Published\", \"Streamed\", \"X Hours Ago\"\n",
    "        publish_date_format = raw_publish_date.split(\" \")[len(raw_publish_date.split(\" \"))-3:len(raw_publish_date.split(\" \"))]\n",
    "\n",
    "        if publish_date_format[1] == \"hours\":\n",
    "            publish_date_convert = datetime.strptime(scrape_date, '%Y-%m-%d')\n",
    "\n",
    "        else:\n",
    "            publish_date_convert = convertDate(publish_date_format)\n",
    "\n",
    "        # Break if Date Less than Input Date Range\n",
    "        if publish_date_convert < converted_input_date:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            published_on.append(publish_date_convert)\n",
    "\n",
    "        # Title\n",
    "        title = video_soup.find(\"title\").text.replace(\" - YouTube\", \"\")\n",
    "        title_videos.append(title)\n",
    "\n",
    "        # Views\n",
    "        string_views = video_soup.find(\"div\", id=\"watch7-views-info\").text.replace(\" views\", \"\").replace(\",\",\"\").replace(\"\\n\",\"\")\n",
    "        int_views = int(string_views)\n",
    "        views.append(int_views)\n",
    "\n",
    "        #Duration\n",
    "        duration = video_soup.find(\"meta\", itemprop=\"duration\").get(\"content\").replace(\"PT\",\"\").split(\"M\")\n",
    "        duration_mins = int(video_soup.find(\"meta\", itemprop=\"duration\").get(\"content\").replace(\"PT\",\"\").split(\"M\")[0])\n",
    "        duration_secs = int(duration[1].replace(\"S\",\"\"))\n",
    "        total_duration = duration_mins + duration_secs/60\n",
    "        duration_videos.append(total_duration)\n",
    "\n",
    "        # Likes\n",
    "        string_likes = video_soup.find(\"button\", title=\"I like this\").text\n",
    "        if string_likes != \"\":\n",
    "            int_likes = int(string_likes.replace(\",\",\"\"))\n",
    "            likes.append(int_likes)\n",
    "        else:\n",
    "            likes.append(0)\n",
    "\n",
    "        # Dislikes\n",
    "        string_dislikes = video_soup.find(\"button\", title=\"I dislike this\").text\n",
    "        if string_dislikes != \"\":\n",
    "            int_dislikes = int(string_dislikes.replace(\",\",\"\"))\n",
    "            dislikes.append(int_dislikes)\n",
    "        else:\n",
    "            dislikes.append(0)\n",
    "\n",
    "        # Category\n",
    "        category = video_soup.find(\"h4\", class_=\"title\", text=\"\\n      Category\\n    \").find_next(\"a\").text\n",
    "        categories.append(category)\n",
    "\n",
    "        # Paid\n",
    "        paid = video_soup.find(\"meta\", itemprop=\"paid\").get(\"content\")\n",
    "        paid_list.append(paid)\n",
    "\n",
    "        # Family Friendly\n",
    "        family = video_soup.find(\"meta\", itemprop=\"isFamilyFriendly\").get(\"content\")\n",
    "        family_friendly.append(family)\n",
    "\n",
    "        percent_complete = round(((i+1) / (len(urls_all)))*100,2)\n",
    "\n",
    "        print(f\"{percent_complete}% complete...\")\n",
    "\n",
    "    urls_to_date = urls_all[0:len(published_on)]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"Artist\" : artist_name,\n",
    "                       \"Scrape_Date\" : scrape_datetime,\n",
    "                       \"Search_Name\" : input_name,\n",
    "                       \"Joined\" : joined_convert,\n",
    "                       \"Subscribers\" : subscribers_int,\n",
    "                       \"Total_Views\" : total_views_int,\n",
    "                       \"Published\": published_on,\n",
    "                       \"Title\" : title_videos,\n",
    "                       \"Category\" : categories,\n",
    "                       \"Duration\" : duration_videos,\n",
    "                       \"Views\" : views,\n",
    "                       \"Likes\" : likes,\n",
    "                       \"Dislikes\" : dislikes,\n",
    "                       \"Paid\" : paid_list,\n",
    "                       \"Family_Friendly\" : family_friendly,\n",
    "                       \"URL\" : urls_to_date,\n",
    "                      })\n",
    "\n",
    "    df = df.sort_values(\"Published\",ascending=False)\n",
    "    \n",
    "    # Saving to CSV\n",
    "    df.to_csv(f\"{artist_name}_scrape.csv\")\n",
    "\n",
    "    # Saving to JSON\n",
    "    df.to_json(f\"../js/{artist_name}_data.js\", orient=\"records\")\n",
    "\n",
    "    # Insert Data into Database\n",
    "    print(\"Inserting data into database...\")\n",
    "    # Creating table for videos\n",
    "    connection.execute(f\"\\\n",
    "    CREATE TABLE IF NOT EXISTS {artist_db_name} (\\\n",
    "    ID INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\\\n",
    "    SCRAPE_DATE DATETIME,\\\n",
    "    SEARCH_NAME VARCHAR(355) CHARACTER SET UTF8MB4,\\\n",
    "    TABLE_NAME VARCHAR(255)CHARACTER SET UTF8MB4,\\\n",
    "    ARTIST VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    PUBLISHED DATE,\\\n",
    "    TITLE VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    CATEGORY VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    DURATION FLOAT,\\\n",
    "    VIEWS INT,\\\n",
    "    LIKES INT,\\\n",
    "    DISLIKES INT,\\\n",
    "    COMMENTS INT,\\\n",
    "    PAID VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    FAMILY_FRIENDLY VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    URL VARCHAR(255) CHARACTER SET UTF8MB4\\\n",
    "    )\")\n",
    "\n",
    "    # Creating Table for Artist data\n",
    "    connection.execute(\"\\\n",
    "    CREATE TABLE IF NOT EXISTS artists(\\\n",
    "    ID INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\\\n",
    "    SCRAPE_DATE DATETIME,\\\n",
    "    SEARCH_NAME VARCHAR(355) CHARACTER SET UTF8MB4,\\\n",
    "    ARTIST VARCHAR(255) CHARACTER SET UTF8MB4,\\\n",
    "    JOINED DATE,\\\n",
    "    SUBSCRIBERS INT,\\\n",
    "    TOTAL_VIEWS INT\\\n",
    "    )\")\n",
    "\n",
    "    # Getting df values and inserting into appropriate tables\n",
    "    for i in range(len(df)):\n",
    "        scrape_date = df.loc[i,\"Scrape_Date\"]\n",
    "        search_name = df.loc[i,\"Search_Name\"]\n",
    "        table_name = artist_db_name\n",
    "        artist = df.loc[i,\"Artist\"]\n",
    "        joined = df.loc[i,\"Joined\"]\n",
    "        subscribers = df.loc[i,\"Subscribers\"]\n",
    "        total_views = df.loc[i,\"Total_Views\"]\n",
    "        published = df.loc[i,\"Published\"]\n",
    "        title = df.loc[i,\"Title\"].replace(\"'\",\"\").replace('\"',\"\").replace(']',\"\")\\\n",
    "        .replace('[',\"\").replace('\\\\',\"\").replace(\"%\",\"\")\n",
    "        category = df.loc[i,\"Category\"]\n",
    "        duration = df.loc[i,\"Duration\"]\n",
    "        views = df.loc[i,\"Views\"]\n",
    "        likes = df.loc[i,\"Likes\"]\n",
    "        dislikes = df.loc[i,\"Dislikes\"]\n",
    "        paid = df.loc[i,\"Paid\"]\n",
    "        family_friendly = df.loc[i,\"Family_Friendly\"]\n",
    "        url =  df.loc[i,\"URL\"]\n",
    "\n",
    "        connection.execute(f\"INSERT INTO {artist_db_name}\\\n",
    "        (SCRAPE_DATE, SEARCH_NAME, TABLE_NAME, ARTIST, PUBLISHED, TITLE, CATEGORY , DURATION,\\\n",
    "        VIEWS, LIKES, DISLIKES, PAID, FAMILY_FRIENDLY, URL)\\\n",
    "        VALUES ('{scrape_date}','{search_name}', '{table_name}', '{artist}', '{published}', '{title}', '{category}',\\\n",
    "        '{duration}', '{views}', '{likes}', '{dislikes}', '{paid}',\\\n",
    "        '{family_friendly}', '{url}')\")\n",
    "\n",
    "    connection.execute(f\"INSERT INTO artists \\\n",
    "    (SCRAPE_DATE, SEARCH_NAME, ARTIST, JOINED, SUBSCRIBERS, TOTAL_VIEWS)\\\n",
    "    VALUES ('{scrape_date}', '{search_name}', '{artist}', '{joined}', '{subscribers}',\\\n",
    "    '{total_views}')\")\n",
    "\n",
    "    print(\"Inserted data into database successfully...\")\n",
    "\n",
    "    # View Data\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
